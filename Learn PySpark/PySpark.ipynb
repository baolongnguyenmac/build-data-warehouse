{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a36a019",
   "metadata": {},
   "source": [
    "**For more information about those session below, access: [this url](https://www.youtube.com/watch?v=_C8kWso4ne4&ab_channel=freeCodeCamp.org)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459868e",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "    - PySpark DataFrame\n",
    "    - Reading the dataset\n",
    "    - Checking the datatype\n",
    "    - Selecting columns and indexing\n",
    "    - Check describe just like pandas\n",
    "    - Adding/Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea585af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.9:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark SQL Server Example - via JDBC</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdd9b971d90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36f7d2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "|star_rating|               title|content_rating|genre|duration|         actors_list|\n",
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "|        9.3|The Shawshank Red...|             R|Crime|     142|[u'Tim Robbins', ...|\n",
      "|        9.2|       The Godfather|             R|Crime|     175|[u'Marlon Brando'...|\n",
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "df = spark.read.csv('./imdb_ratings.csv', header=True, inferSchema=True)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a446fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- star_rating: double (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content_rating: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- actors_list: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pd.df.info()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1024158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(star_rating=9.3, title='The Shawshank Redemption', content_rating='R', genre='Crime', duration=142, actors_list=\"[u'Tim Robbins', u'Morgan Freeman', u'Bob Gunton']\"),\n",
       " Row(star_rating=9.2, title='The Godfather', content_rating='R', genre='Crime', duration=175, actors_list=\"[u'Marlon Brando', u'Al Pacino', u'James Caan']\")]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same thing with pd.df.head(2)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8e7c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               title|genre|\n",
      "+--------------------+-----+\n",
      "|The Shawshank Red...|Crime|\n",
      "|       The Godfather|Crime|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select column(s), but return a dataframe\n",
    "# you can see the data in dataframe\n",
    "star_rating = df.select('star_rating')\n",
    "title_genre = df.select(['title', 'genre'])\n",
    "title_genre.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c2492ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'star_rating'>\n",
      "DataFrame[star_rating: double, genre: string]\n"
     ]
    }
   ],
   "source": [
    "# select column(s) and return a column or a dataframe\n",
    "print(df['star_rating']) # return a column, can you .show() to see the data\n",
    "print(df[['star_rating', 'genre']]) # return a dataframe, just use .show() to see the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d30f3a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('star_rating', 'double'),\n",
       " ('title', 'string'),\n",
       " ('content_rating', 'string'),\n",
       " ('genre', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('actors_list', 'string')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hiển thị kiểu dữ liệu của các cột \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3736cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+--------------+-------+------------------+--------------------+\n",
      "|summary|        star_rating|               title|content_rating|  genre|          duration|         actors_list|\n",
      "+-------+-------------------+--------------------+--------------+-------+------------------+--------------------+\n",
      "|  count|                979|                 979|           976|    979|               979|                 979|\n",
      "|   mean| 7.8897854954034985|               796.0|          null|   null|120.97957099080695|                null|\n",
      "| stddev|0.33606932614795176|   1090.190808987124|          null|   null|26.218009846412077|                null|\n",
      "|    min|                7.4|(500) Days of Summer|      APPROVED| Action|                64|\"[u\"\"Brian O'Hall...|\n",
      "|    max|                9.3|               [Rec]|             X|Western|               242|[u'Zooey Deschane...|\n",
      "+-------+-------------------+--------------------+--------------+-------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54f17a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979, 6)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5efa7ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+-----+--------+--------------------+----+-----+\n",
      "|star_rating|               title|content_rating|genre|duration|         actors_list|hola|hello|\n",
      "+-----------+--------------------+--------------+-----+--------+--------------------+----+-----+\n",
      "|        9.3|The Shawshank Red...|             R|Crime|     142|[u'Tim Robbins', ...|  69|  426|\n",
      "|        9.2|       The Godfather|             R|Crime|     175|[u'Marlon Brando'...|  69|  525|\n",
      "+-----------+--------------------+--------------+-----+--------+--------------------+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add column: luôn luôn phải đính kèm giá trị \n",
    "            # hoặc sửa data trong column đó (chuẩn hóa data)\n",
    "            # link chuẩn hóa đã được bookmark\n",
    "df = df.withColumn('hello', df['duration'] * 2 + df['duration'])\n",
    "df = df.withColumn('hola', sf.lit(69))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32e83f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "|star_rating|               title|content_rating|genre|duration|         actors_list|\n",
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "|        9.3|The Shawshank Red...|             R|Crime|     142|[u'Tim Robbins', ...|\n",
      "|        9.2|       The Godfather|             R|Crime|     175|[u'Marlon Brando'...|\n",
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop column\n",
    "df = df.drop('hello', 'hola')\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b37ec4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+-----+--------------+--------------------+\n",
      "|star_rating|               title|content_rating|genre|still duration|         actors_list|\n",
      "+-----------+--------------------+--------------+-----+--------------+--------------------+\n",
      "|        9.3|The Shawshank Red...|             R|Crime|           142|[u'Tim Robbins', ...|\n",
      "|        9.2|       The Godfather|             R|Crime|           175|[u'Marlon Brando'...|\n",
      "+-----------+--------------------+--------------+-----+--------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('duration', 'still duration')\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd01e6",
   "metadata": {},
   "source": [
    "## Part 2: Handling with missing value\n",
    "\n",
    "    - Dropping columns (missing >= 50%)\n",
    "    - Dropping rows (missing >= 50%)\n",
    "    - bla\n",
    "    - Handling missing value by mean, median, mode,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4292438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+----+----------+------------+\n",
      "| id|session|timestamp1| id2|None value|None value 1|\n",
      "+---+-------+----------+----+----------+------------+\n",
      "|  1|      1|         1| 3.0|         1|           1|\n",
      "|  2|      1|         2| 5.0|         2|           2|\n",
      "|  3|      8|         3| NaN|      null|        null|\n",
      "|  4|   null|         4|null|      null|        null|\n",
      "|  5|      3|         5|10.0|      null|        null|\n",
      "|  6|      4|         6| NaN|      null|        null|\n",
      "|  7|      2|      null| NaN|      null|        null|\n",
      "+---+-------+----------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1,1, 1, 3.0, 1, '1'),\n",
    "    (2,1, 2, float(5), 2, '2'),\n",
    "    (3,8, 3, np.nan, None, None),\n",
    "    (4,None, 4, None, None, None),\n",
    "    (5,3, 5, float(10), None, None),\n",
    "    (6,4, 6, float(\"nan\"), None, None),\n",
    "    (7,2, None, float(\"nan\"), None, None),\n",
    "]\n",
    "df = spark.createDataFrame(data, (\"id\", \"session\", \"timestamp1\", \"id2\", \"None value\", \"None value 1\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3d08923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+---+----------+------------+\n",
      "| id|session|timestamp1|id2|None value|None value 1|\n",
      "+---+-------+----------+---+----------+------------+\n",
      "|  1|      1|         1|3.0|         1|           1|\n",
      "|  2|      1|         2|5.0|         2|           2|\n",
      "+---+-------+----------+---+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop all rows that contain NULL or NaN\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9662807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+----+----------+------------+\n",
      "| id|session|timestamp1| id2|None value|None value 1|\n",
      "+---+-------+----------+----+----------+------------+\n",
      "|  1|      1|         1| 3.0|         1|           1|\n",
      "|  2|      1|         2| 5.0|         2|           2|\n",
      "|  5|      3|         5|10.0|      null|        null|\n",
      "+---+-------+----------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xóa các dòng có số attribute null >= (len(df.columns)//2+1)\n",
    "df.na.drop(thresh=len(df.columns)//2+1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84690b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+----+----------+------------+\n",
      "| id|session|timestamp1| id2|None value|None value 1|\n",
      "+---+-------+----------+----+----------+------------+\n",
      "|  1|      1|         1| 3.0|         1|           1|\n",
      "|  2|      1|         2| 5.0|         2|           2|\n",
      "|  5|      3|         5|10.0|      null|        null|\n",
      "+---+-------+----------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xóa các dòng có session và id2 chứa null (chỉ xét trong 2 cột này)\n",
    "df.na.drop(subset=['session', 'id2'], how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adc1ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- session: long (nullable = true)\n",
      " |-- timestamp1: long (nullable = true)\n",
      " |-- id2: double (nullable = true)\n",
      " |-- None value: long (nullable = true)\n",
      " |-- None value 1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xóa các cột có trên 50% là null???\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f8c578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+-------+----------+------------+\n",
      "| id|session|timestamp1|    id2|None value|None value 1|\n",
      "+---+-------+----------+-------+----------+------------+\n",
      "|  1|      1|         1|    3.0|         1|           1|\n",
      "|  2|      1|         2|    5.0|         2|           2|\n",
      "|  3|      8|         3|10000.0|     10000|        null|\n",
      "|  4|  10000|         4|10000.0|     10000|        null|\n",
      "|  5|      3|         5|   10.0|     10000|        null|\n",
      "|  6|      4|         6|10000.0|     10000|        null|\n",
      "|  7|      2|     10000|10000.0|     10000|        null|\n",
      "+---+-------+----------+-------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill missing value with specific value\n",
    "# nhớ để ý kiểu dữ liệu: điền khuyết bằng string sẽ chỉ áp dụng cho các cột string, \n",
    "#                        điền số sẽ chỉ áp cho các cột số\n",
    "df.na.fill(10000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "63b16037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+----+----------+------------+\n",
      "| id|session|timestamp1| id2|None value|None value 1|\n",
      "+---+-------+----------+----+----------+------------+\n",
      "|  1|      1|         1| 3.0|         1|           1|\n",
      "|  2|      1|         2| 5.0|         2|           2|\n",
      "|  3|      8|         3| NaN|      null|        null|\n",
      "|  4|   null|         4|null|      null|        null|\n",
      "|  5|      3|         5|10.0|      null|        null|\n",
      "|  6|      4|         6| NaN|      null|        null|\n",
      "|  7|      2|      null| NaN|      null|        null|\n",
      "+---+-------+----------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e2465dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+----+----------+------------+--------+----+\n",
      "| id|session|timestamp1| id2|None value|None value 1|session_|id2_|\n",
      "+---+-------+----------+----+----------+------------+--------+----+\n",
      "|  1|      1|         1| 3.0|         1|           1|       1| 3.0|\n",
      "|  2|      1|         2| 5.0|         2|           2|       1| 5.0|\n",
      "|  3|      8|         3| NaN|      null|        null|       8| 5.0|\n",
      "|  4|   null|         4|null|      null|        null|       2| 5.0|\n",
      "|  5|      3|         5|10.0|      null|        null|       3|10.0|\n",
      "|  6|      4|         6| NaN|      null|        null|       4| 5.0|\n",
      "|  7|      2|      null| NaN|      null|        null|       2| 5.0|\n",
      "+---+-------+----------+----+----------+------------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# điền khuyết cho một vài cột nhất định\n",
    "# session, id2 = mean/mode/median\n",
    "imputer = Imputer(inputCols=['session', 'id2'], \n",
    "                  outputCols=[f'{c}_' for c in ['session', 'id2']], \n",
    "                  strategy='median') # mode, median,...\n",
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930904e0",
   "metadata": {},
   "source": [
    "## Part 3 - Filter\n",
    "\n",
    "    - Filter\n",
    "    - &, |, ==\n",
    "    - ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0dff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "182e7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "|star_rating|               title|content_rating|genre|duration|         actors_list|\n",
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "|        9.3|The Shawshank Red...|             R|Crime|     142|[u'Tim Robbins', ...|\n",
      "|        9.2|       The Godfather|             R|Crime|     175|[u'Marlon Brando'...|\n",
      "|        9.1|The Godfather: Pa...|             R|Crime|     200|[u'Al Pacino', u'...|\n",
      "+-----------+--------------------+--------------+-----+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('./imdb_ratings.csv', header=True, inferSchema=True)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "291465a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+------+--------+--------------------+\n",
      "|star_rating|               title|content_rating| genre|duration|         actors_list|\n",
      "+-----------+--------------------+--------------+------+--------+--------------------+\n",
      "|        9.3|The Shawshank Red...|             R| Crime|     142|[u'Tim Robbins', ...|\n",
      "|        9.2|       The Godfather|             R| Crime|     175|[u'Marlon Brando'...|\n",
      "|        9.0|     The Dark Knight|         PG-13|Action|     152|[u'Christian Bale...|\n",
      "|        8.9|        Pulp Fiction|             R| Crime|     154|[u'John Travolta'...|\n",
      "+-----------+--------------------+--------------+------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the movies whose durations >= 200\n",
    "# return a dataframe \n",
    "df.filter(~(df['duration']>=200) & (df['genre']=='Crime') | (df.star_rating==9.)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c4fdfa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+---------+--------+--------------------+\n",
      "|star_rating|               title|content_rating|    genre|duration|         actors_list|\n",
      "+-----------+--------------------+--------------+---------+--------+--------------------+\n",
      "|        9.3|The Shawshank Red...|             R|    Crime|     142|[u'Tim Robbins', ...|\n",
      "|        9.2|       The Godfather|             R|    Crime|     175|[u'Marlon Brando'...|\n",
      "|        9.1|The Godfather: Pa...|             R|    Crime|     200|[u'Al Pacino', u'...|\n",
      "|        9.0|     The Dark Knight|         PG-13|   Action|     152|[u'Christian Bale...|\n",
      "|        8.9|        Pulp Fiction|             R|    Crime|     154|[u'John Travolta'...|\n",
      "|        8.9|        12 Angry Men|     NOT RATED|    Drama|      96|[u'Henry Fonda', ...|\n",
      "|        8.9|The Good, the Bad...|     NOT RATED|  Western|     161|[u'Clint Eastwood...|\n",
      "|        8.9|The Lord of the R...|         PG-13|Adventure|     201|[u'Elijah Wood', ...|\n",
      "|        8.9|    Schindler's List|             R|Biography|     195|[u'Liam Neeson', ...|\n",
      "|        8.9|          Fight Club|             R|    Drama|     139|[u'Brad Pitt', u'...|\n",
      "|        8.8|The Lord of the R...|         PG-13|Adventure|     178|[u'Elijah Wood', ...|\n",
      "+-----------+--------------------+--------------+---------+--------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6c12a",
   "metadata": {},
   "source": [
    "## Work with SQLServer\n",
    "\n",
    "    - Demo CRUD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c661588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.9:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff6221b1df0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql import * \n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "819e11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOSTNAME = \"localhost\"\n",
    "PORT = 1433\n",
    "USERNAME = \"sa\"\n",
    "PASSWORD = \"Longhandsome123\"\n",
    "# DB_NAME = \"demo\"\n",
    "\n",
    "def createUrl(dbName, hostname=HOSTNAME, port=PORT, username=USERNAME, password=PASSWORD):\n",
    "    return f\"jdbc:sqlserver://{hostname}:{port};database={dbName};user={username};password={password}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a38852f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, 'Nguyen Bao Long', '0919070940'),\n",
    "    (2, 'Bao Long', '09'),\n",
    "    (3, 'Nguyen Bao', '0940'),\n",
    "]\n",
    "    \n",
    "# write to a table into demo db (create)\n",
    "df = spark.createDataFrame(data, (\"id\", \"name\", \"phone\"))\n",
    "df.printSchema()\n",
    "df.write.jdbc(url=createUrl(dbName='demo'), table='customer_order', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f757785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append a row into demo db (update)\n",
    "id_customer = 4\n",
    "name = \"Bảo Long Nguyễn\"\n",
    "phone = '01923'\n",
    "\n",
    "df = spark.createDataFrame([(id_customer, name, phone)], ('id', 'name', 'phone'))\n",
    "df.write.jdbc(createUrl(dbName='demo'), table='customer_order', mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "414b0d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+----------+\n",
      "| id|           name|     phone|\n",
      "+---+---------------+----------+\n",
      "|  2|       Bao Long|        09|\n",
      "|  1|Nguyen Bao Long|0919070940|\n",
      "+---+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query in table\n",
    "query = '''\n",
    "    (SELECT *\n",
    "    FROM customer_order as co\n",
    "    WHERE co.id = 1\n",
    "        OR co.id = 2) t\n",
    "'''\n",
    "df = spark.read.jdbc(createUrl(dbName='demo'), table=query)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d8e3b478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+----------+\n",
      "| id|           name|     phone|\n",
      "+---+---------------+----------+\n",
      "|  1|Nguyen Bao Long|0919070940|\n",
      "|  2|       Bao Long|        09|\n",
      "|  3|     Nguyen Bao|      0940|\n",
      "+---+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data to df\n",
    "df = spark.read.jdbc(createUrl(dbName='demo'), table='customer_order')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec97e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+----------+\n",
      "|        id|           name|     phone|\n",
      "+----------+---------------+----------+\n",
      "|0919070940|Nguyen Bao Long|0919070940|\n",
      "|        09|       Bao Long|        09|\n",
      "|        69|     Nguyen Bao|      0940|\n",
      "+----------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# update\n",
    "df.withColumn(\n",
    "    'id',\n",
    "    sf.when((df.phone=='0940') | (df.phone=='019'), '69')\n",
    "    .otherwise(df.phone)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "032894ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|     phone|\n",
      "+---+----------+\n",
      "|  1|0919070940|\n",
      "|  2|        09|\n",
      "|  3|      0940|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete column\n",
    "df.drop(df.name).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd0304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete row\n",
    "'''\n",
    "    - có vẻ như spark không có cơ chế xóa như vậy\n",
    "    --> giải quyết bằng cách lọc ra những thằng k cần xóa, bỏ những thằng đó vào 1 df mới và thao tác trên df đó\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
